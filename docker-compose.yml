version: '3'

services:
  # ZooKeeper é um serviço centralizado para manter informações de configurações.
  # nomeação, fornecendo sincronização distribuída e fornecendo serviços de grupo.
  # Fornece coordenação distribuída para nosso cluster Kafka.
  # http://zookeeper.apache.org/
  zookeeper:
    image: zookeeper:3.4.9
    # ZooKeeper foi projetado para "falhar rapidamente", por isso é importante permitir que ele
    # reinicie automaticamente.
    restart: unless-stopped
    hostname: zookeeper
    # Exporemos a porta do cliente ZK para que possamos nos conectar a ela a partir de nossos aplicativos.
    ports:
      - "2181:2181"
    volumes:
      - ./volumes/zookeeper/data:/data
      - ./volumes/zookeeper/datalog:/datalog

  # Kafka é uma plataforma de streaming distribuída. É usado para construir streaming em tempo real
  # pipelines de dados que movem dados de maneira confiável entre sistemas e plataformas e para construir
  # aplicativos de streaming em tempo real que transformam ou reagem aos fluxos de dados.
  # http://kafka.apache.org/
  kafka:
    image: confluentinc/cp-kafka:4.1.0
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      # Obrigatório. Kafka publicará este endereço no ZooKeeper para que os clientes saibam
      # como entrar em contato com Kafka. "PLAINTEXT" indica que nenhuma autenticação
      # mecanismo será usado.
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"
      # Obrigatório. Instrui Kafka sobre como entrar em contato com o ZooKeeper.
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      # Obrigatório ao executar em um cluster de nó único, como nós. Seríamos capazes de assumir o padrão se tivéssemos
      # três ou mais nós no cluster.
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ./volumes/kafka/data:/var/lib/kafka/data
    # Como o Kafka depende do ZooKeeper, isso instruirá o docker a esperar até o serviço do zookeeper
    # está ativo antes de tentar iniciar o Kafka.
    depends_on:
      - zookeeper

  # Escrito e de código aberto pelo Confluent, o Schema Registry para Apache Kafka permite
  # desenvolvedores para definir esquemas padrão para seus eventos, compartilhá-los entre os
  # organizá-los e desenvolvê-los com segurança de uma forma que seja compatível com as versões anteriores e à prova de futuro.
  # https://www.confluent.io/confluent-schema-registry/
  schema-registry:
    image: confluentinc/cp-schema-registry:4.1.0
    hostname: schema-registry
    restart: unless-stopped
    ports:
      - "8081:8081"
    environment:
      # Obrigatório. Schema Registry entrará em contato com o ZooKeeper para descobrir como se conectar
      # para o cluster Kafka.
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181
      # Obrigatório. Este é o nome do host que o Schema Registry anunciará no ZooKeeper.
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
    # O Schema Registry depende do Kafka e do ZooKeeper. Isso instruirá o docker a esperar
    # até que os serviços zookeeper e kafka estejam ativos antes de tentar iniciar o Schema Registry.
    depends_on:
      - zookeeper
      - kafka

  # Uma ferramenta da web que permite criar / visualizar / pesquisar / evoluir / visualizar
  # histórico e configurar esquemas Avro de seu cluster Kafka.
  # https://github.com/Landoop/schema-registry-ui
  schema-registry-ui:
    image: landoop/schema-registry-ui:0.9.4
    hostname: schema-registry-ui
    # schema-registry-ui se liga à porta 8000, mas vamos expô-lo em nosso local
    # máquina na porta 8001.
    ports:
      - "8001:8000"
    environment:
      # Obrigatório. Instrui a UI onde pode encontrar o registro do esquema.
      SCHEMAREGISTRY_URL: http://schema-registry:8081/
      # Isso instrui a imagem do docker a usar o Caddy para fazer proxy do tráfego para o schema-registry-ui.
      PROXY: "true"
    # Como esta é uma UI para o Schema Registry, contamos com o Schema Registry. Docker vai esperar por
    # o serviço de registro de esquema deve ser ativado antes de iniciar o ui de registro de esquema.
    depends_on:
      - schema-registry

  # O Kafka REST Proxy fornece uma interface RESTful para um cluster Kafka.
  # Torna mais fácil produzir e consumir mensagens, ver o estado
  # do cluster e realizar ações administrativas sem usar
  # o protocolo ou clientes nativos do Kafka.
  # https://github.com/confluentinc/kafka-rest
  kafka-rest-proxy:
    image: confluentinc/cp-kafka-rest:4.1.0
    hostname: kafka-rest-proxy
    ports:
      - "8082:8082"
    environment:
      # Specifies the ZooKeeper connection string. This service connects
      # to ZooKeeper so that it can broadcast its endpoints as well as
      # react to the dynamic topology of the Kafka cluster.
      KAFKA_REST_ZOOKEEPER_CONNECT: zookeeper:2181
      # The address on which Kafka REST will listen for API requests.
      KAFKA_REST_LISTENERS: http://0.0.0.0:8082/
      # The base URL for Schema Registry that should be used by the Avro serializer.
      KAFKA_REST_SCHEMA_REGISTRY_URL: http://schema-registry:8081/
      # Required. This is the hostname used to generate absolute URLs in responses.
      # It defaults to the Java canonical hostname for the container, which might
      # not be resolvable in a Docker environment.
      KAFKA_REST_HOST_NAME: kafka-rest-proxy
      # The list of Kafka brokers to connect to. This is only used for bootstrapping,
      # the addresses provided here are used to initially connect to the cluster,
      # after which the cluster will dynamically change. Thanks, ZooKeeper!
      KAFKA_REST_BOOTSTRAP_SERVERS: kafka:9092
    # Kafka REST relies upon Kafka, ZooKeeper, and Schema Registry.
    # This will instruct docker to wait until those services are up
    # before attempting to start Kafka REST.
    depends_on:
      - zookeeper
      - kafka
      - schema-registry

  # Browse Kafka topics and understand what's happening on your cluster.
  # Find topics / view topic metadata / browse topic data
  # (kafka messages) / view topic configuration / download data.
  # https://github.com/Landoop/kafka-topics-ui
  kafka-topics-ui:
    image: landoop/kafka-topics-ui:0.9.3
    hostname: kafka-topics-ui
    ports:
      - "8000:8000"
    environment:
      # Required. Instructs the UI where it can find the Kafka REST Proxy.
      KAFKA_REST_PROXY_URL: "http://kafka-rest-proxy:8082/"
      # This instructs the docker image to use Caddy to proxy traffic to kafka-topics-ui.
      PROXY: "true"
    # kafka-topics-ui relies upon Kafka REST.
    # This will instruct docker to wait until those services are up
    # before attempting to start kafka-topics-ui.
    depends_on:
      - kafka-rest-proxy

  # Kafka Connect, an open source component of Apache Kafka,
  # is a framework for connecting Kafka with external systems
  # such as databases, key-value stores, search indexes, and file systems.
  # https://docs.confluent.io/current/connect/index.html
  kafka-connect:
    image: confluentinc/cp-kafka-connect:4.1.0
    hostname: kafka-connect
    ports:
      - "8083:8083"
    environment:
      # Required.
      # The list of Kafka brokers to connect to. This is only used for bootstrapping,
      # the addresses provided here are used to initially connect to the cluster,
      # after which the cluster can dynamically change. Thanks, ZooKeeper!
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      # Required. A unique string that identifies the Connect cluster group this worker belongs to.
      CONNECT_GROUP_ID: compose-connect-group
      # Connect will actually use Kafka topics as a datastore for configuration and other data. #meta
      # Required. The name of the topic where connector and task configuration data are stored.
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      # Required. The name of the topic where connector and task configuration offsets are stored.
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      # Required. The name of the topic where connector and task configuration status updates are stored.
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      # Required. Converter class for key Connect data. This controls the format of the
      # data that will be written to Kafka for source connectors or read from Kafka for sink connectors.
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      # Allows connect to leverage the power of schema registry. Here we define it for key schemas.
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      # Required. Converter class for value Connect data. This controls the format of the
      # data that will be written to Kafka for source connectors or read from Kafka for sink connectors.
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      # Allows connect to leverage the power of schema registry. Here we define it for value schemas.
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      # Required. Converter class for internal key Connect data that implements the Converter interface.
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      # Required. Converter class for offset value Connect data that implements the Converter interface.
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      # Required. The hostname that will be given out to other workers to connect to.
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      # The next three are required when running in a single-node cluster, as we are.
      # We would be able to take the default (of 3) if we had three or more nodes in the cluster.
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
    # kafka-connect relies upon Kafka and ZooKeeper.
    # This will instruct docker to wait until those services are up
    # before attempting to start kafka-connect.
    depends_on:
      - zookeeper
      - kafka

  # This is a web tool for Kafka Connect for setting up and managing connectors for multiple connect clusters.
  # https://github.com/Landoop/kafka-connect-ui
  kafka-connect-ui:
    image: landoop/kafka-connect-ui:0.9.4
    hostname: kafka-connect-ui
    # kafka-connect-ui binds to port 8000, but we are going to expose it on our local
    # machine on port 8002.
    ports:
      - "8002:8000"
    environment:
      # Required. Instructs the UI where it can find Kafka Connect.
      CONNECT_URL: "http://kafka-connect:8083/"
      # This instructs the docker image to use Caddy to proxy traffic to kafka-connect-ui.
      PROXY: "true"
    # kafka-connect-ui relies upon Kafka Connect.
    # This will instruct docker to wait until those services are up
    # before attempting to start kafka-connect-ui.
    depends_on:
      - kafka-connect

  # API for ZooNavigator, web-based browser & editor for ZooKeeper.
  # https://github.com/elkozmon/zoonavigator-api
  zoonavigator-api:
    image: elkozmon/zoonavigator-api:0.4.0
    environment:
      # The port on which the api service will listen for incoming connections.
      SERVER_HTTP_PORT: 9000
    restart: unless-stopped
    # zoonavigator-api relies upon ZooKeeper.
    # This will instruct docker to wait until those services are up
    # before attempting to start zoonavigator-api.
    depends_on:
      - zookeeper

  # Web client for ZooNavigator, web-based browser & editor for ZooKeeper.
  # https://github.com/elkozmon/zoonavigator-web
  zoonavigator-web:
    image: elkozmon/zoonavigator-web:0.4.0
    # zoonavigator-web binds to port 8000, but we are going to expose it on our local
    # machine on port 8002.
    ports:
      - "8003:8000"
    environment:
      # The following two keys instruct the web component how to connect to
      # the backing api component.
      API_HOST: "zoonavigator-api"
      API_PORT: 9000
    # zoonavigator-web relies upon zoonavigator-api.
    # This will instruct docker to wait until those services are up
    # before attempting to start zoonavigator-web.
    depends_on:
      - zoonavigator-api
    restart: unless-stopped

  # KSQL is the open source streaming SQL engine for Apache Kafka.
  # It provides an easy-to-use yet powerful interactive SQL
  # interface for stream processing on Kafka, without the need to write code
  # in a programming language such as Java or Python. KSQL is scalable, elastic,
  # fault-tolerant, and real-time. It supports a wide range of streaming operations,
  # including data filtering, transformations, aggregations, joins, windowing, and sessionization.
  # https://docs.confluent.io/current/ksql/docs/
  ksql-server:
    image: confluentinc/cp-ksql-server:5.0.0
    ports:
      - "8088:8088"
    environment:
      # Required.
      # The list of Kafka brokers to connect to. This is only used for bootstrapping,
      # the addresses provided here are used to initially connect to the cluster,
      # after which the cluster can dynamically change. Thanks, ZooKeeper!
      KSQL_BOOTSTRAP_SERVERS: kafka:9092
      # Controls the REST API endpoint for the KSQL server.
      KSQL_LISTENERS: http://0.0.0.0:8088
      # The Schema Registry URL path to connect KSQL to.
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
    # ksql-server relies upon Kafka and Schema Registry.
    # This will instruct docker to wait until those services are up
    # before attempting to start ksql-server.
    depends_on:
      - kafka
      - schema-registry